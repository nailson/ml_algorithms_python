{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  actual_status predicted_status\n0      Positive         Positive\n1      Positive         Negative\n2      Negative         Positive\n3      Negative         Negative\n4      Negative         Positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual_status</th>\n      <th>predicted_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Positive</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Positive</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Negative</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Negative</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Negative</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(columns=['actual_status', 'predicted_status'],\n",
    "                   data=[\n",
    "                       ['Positive', 'Positive'],\n",
    "                       ['Positive', 'Negative'],\n",
    "                       ['Negative', 'Positive'],\n",
    "                       ['Negative', 'Negative'],\n",
    "                       ['Negative', 'Positive'],\n",
    "                       ['Negative', 'Negative'],\n",
    "                       ['Negative', 'Positive'],\n",
    "                       ['Negative', 'Negative'],\n",
    "                       ['Positive', 'Negative'],\n",
    "                       ['Positive', 'Negative'],\n",
    "                       ['Positive', 'Negative'],\n",
    "                       ['Positive', 'Positive'],\n",
    "                       ['Positive', 'Negative'],\n",
    "                       ['Negative', 'Positive'],\n",
    "                       ['Negative', 'Negative'],\n",
    "                       ['Negative', 'Negative'],\n",
    "                       ['Negative', 'Negative']\n",
    "                   ])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Negative    10\nPositive     7\nName: actual_status, dtype: int64"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "data.actual_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{(True, True): 2, (True, False): 5, (False, True): 4, (False, False): 6}"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "from collections import Counter\n",
    "confusion_dict = dict(Counter((row.actual_status == 'Positive', row.predicted_status == 'Positive') for index, row in data.iterrows()))\n",
    "\n",
    "confusion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'TP': 2, 'FP': 6, 'FN': 5}"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "confusion_dict['TP'] = confusion_dict.pop((True, True))\n",
    "confusion_dict['FP'] = confusion_dict.pop((False, True))\n",
    "confusion_dict['FN'] = confusion_dict.pop((True, False))\n",
    "confusion_dict['FP'] = confusion_dict.pop((False, False))\n",
    "\n",
    "confusion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{(True, True): 2, (True, False): 5, (False, True): 4, (False, False): 6}"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "def confusion_dict(y_real, y_pred):\n",
    "    df = pd.DataFrame({'y_real':y_real, 'y_pred':y_pred})\n",
    "    confusion_dict = dict(Counter((row.y_real == 'Positive', \n",
    "                                   row.y_pred == 'Positive') for index, row in df.iterrows()))\n",
    "    return  confusion_dict\n",
    "\n",
    "confusion_dict(data.actual_status, data.predicted_status)"
   ]
  }
 ]
}